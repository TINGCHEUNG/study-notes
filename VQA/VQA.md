# Visual Question Answering(VQA) Summary

## Papers

### Surveys

> Information fusion in visual question answering: A Survey (2019)
[paper](https://www.sciencedirect.com/science/article/pii/S1566253518308893)

> Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge (CVPR2018)
[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Teney_Tips_and_Tricks_CVPR_2018_paper.pdf)

> Visual Question Answering: Datasets, Methods, Challenges and Oppurtunities (2018)
[paper](https://www.cs.princeton.edu/courses/archive/spring18/cos598B/public/projects/LiteratureReview/COS598B_spr2018_VQAreview.pdf)

> An Analysis of Visual Question Answering Algorithms (ICCV2017)
[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Kafle_An_Analysis_of_ICCV_2017_paper.pdf)

> Visual question answering: Datasets, algorithms, and future challenges (2017)
[paper](https://www.sciencedirect.com/science/article/pii/S1077314217301170)

> Visual question answering: A survey of methods and datasets (2017)
[paper](https://www.sciencedirect.com/science/article/pii/S1077314217300772)

> Survey of Visual Question Answering: Datasets and Techniques (2017)
[paper](https://arxiv.org/pdf/1705.03865.pdf)

### Based on Knowledge

> Building a Large-scale Multimodal Knowledge Base System for Answering Visual Queries 
[paper](https://arxiv.org/abs/1507.05670)

> Ask Me Anything: Free-form Visual Question AnsweringBased on Knowledge from External Sources (cvpr2016) 
[paper](https://arxiv.org/abs/1511.06973)

> FVQA: Fact-based Visual Question Answering 
[paper](https://arxiv.org/abs/1606.05433)

> Explicit Knowledge-based Reasoning for Visual Question Answering (IJCAI2017)
[paper](https://www.ijcai.org/proceedings/2017/179)
[blog](https://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/80851407)

> Knowledge Acquisition for Visual Question Answering via Iterative Querying (cvpr2017)
[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhu_Knowledge_Acquisition_for_CVPR_2017_paper.pdf)

> R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual Question Answering (KDD2018)
[paper](https://arxiv.org/abs/1805.09701)
[code](https://github.com/lupantech/rvqa)

> Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding (NeurIPS 2018)
[paper](https://arxiv.org/abs/1810.02338)
[code](https://github.com/kexinyi/ns-vqa)
[blog1](https://zhuanlan.zhihu.com/p/61533835)
[blog2](https://zhuanlan.zhihu.com/p/46392910)

> Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering (NIPS2018)
[paper](https://arxiv.org/abs/1811.00538)

> Estimating Node Importance in Knowledge Graphs Using Graph Neural Networks (KDD2019)
[paper](https://arxiv.org/abs/1905.08865)

> From Strings to Things: Knowledge-enabled VQA Models that can Read and Reason (ICCV2019)
[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Singh_From_Strings_to_Things_Knowledge-Enabled_VQA_Model_That_Can_Read_ICCV_2019_paper.pdf)

> Learning to Compose Dynamic Tree Structures for Visual Contexts (cvpr2019)
[paper](https://zpascal.net/cvpr2019/Tang_Learning_to_Compose_Dynamic_Tree_Structures_for_Visual_Contexts_CVPR_2019_paper.pdf)

> KVQA: Knowledge-aware Visual Question Answering(AAAI2019)
[paper](https://www.aaai.org/ojs/index.php/AAAI/article/view/4915)
[code](http://malllabiisc.github.io/resources/kvqa/)

> OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge (cvpr2019)
[paper](https://arxiv.org/abs/1906.00067)

> MUREL: Multimodal Relational Reasoning for Visual Question Answering (cvpr2019)
[paper](https://arxiv.org/abs/1902.09487)
[code](https://github.com/Cadene/murel.bootstrap.pytorch)
[blog](https://zhuanlan.zhihu.com/p/94553059)

> WK-VQA(need feedback in GitHub)
[paper](https://github.com/sanket0211/WK-VQA/)


### Based on GNN

> Graph Reasoning Networks for Visual Question Answering (Arxiv)
[paper](https://arxiv.org/pdf/1907.09815.pdf)

> Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering (NIPS2018)
[paper](https://arxiv.org/abs/1811.00538)

> Relation-aware Graph Attention Network for Visual Question Answering (ICCV2019)
[paper](https://arxiv.org/pdf/1903.12314.pdf)
[blog](https://zhuanlan.zhihu.com/p/63820622)
[code](https://github.com/linjieli222/VQA_ReGAT)

### Based on ML

> Learning Visual Question Answering byBootstrapping Hard Attention
[paper](https://arxiv.org/pdf/1808.00300.pdf)
[blog](https://zhuanlan.zhihu.com/p/41546921)

> BLOCK: Bilinear Superdiagonal Fusion for Visual Question Answering and Visual Relationship Detection
[paper](https://arxiv.org/abs/1902.00038)
[code](https://github.com/Cadene/block.bootstrap.pytorch)

> awesome-vqa [link](https://github.com/chingyaoc/awesome-vqa)

### Relational Reasoning

> A simple neural network module for relational reasoning
[paper](https://arxiv.org/pdf/1706.01427.pdf)

## GitHub link about VQA

### VQA Summary(综述)

#### Summary

[视觉问答（VQA）综述](https://github.com/seagle0128/Algorithm_Interview_Notes-Chinese/blob/master/_papers/QA-%E8%A7%86%E8%A7%89%E9%97%AE%E7%AD%94-A-%E7%BB%BC%E8%BF%B0.md)  
[Knowledge-Based Visual Reasoning (dynamic updating)](https://github.com/Sympathize/vkr-papers)  
[Awesome_VQA](https://github.com/waallf/Awesome_VQA)

#### codes

https://github.com/liuzhi136/Visual-Question-Answering  
https://github.com/anantzoid/VQA-Keras-Visual-Question-Answering  
https://github.com/paarthneekhara/neural-vqa-tensorflow  
https://github.com/Cadene/block.bootstrap.pytorch  
https://github.com/Cadene/vqa.pytorch  
https://github.com/KaihuaTang/VQA2.0-Recent-Approachs-2018.pytorch  
https://github.com/peteanderson80/bottom-up-attention  
https://github.com/paarthneekhara/neural-vqa-tensorflow

## Other links about VQA

> 最新7篇视觉问答（VQA）相关论文—解释、读写记忆网络、逆视觉问答、视觉推理、可解释性、注意力机制、计数 [link](https://cloud.tencent.com/developer/article/1086325)

> 一文带你了解深度学习中的视觉问答（VQA）技术 [link](https://zhuanlan.zhihu.com/p/34312290)

> 「自然语言处理(NLP)」---亚马逊QA(含源码) && 视觉问答QA [link](https://zhuanlan.zhihu.com/p/78357484)

> 【CV+NLP】更有智慧的眼睛：图像描述（Image Caption）&视觉问答（VQA）综述 [link](https://zhuanlan.zhihu.com/p/52499758)

> 一文看懂深度学习中的VQA(视觉问答)技术 [link1](https://zhuanlan.zhihu.com/p/35305264) [link2](https://www.jianshu.com/p/76d2e081e303)

> 基于深度学习的VQA（视觉问答）技术 [link](https://zhuanlan.zhihu.com/p/22530291)

## Application about VQA

1. image retrieval
2. aided-navigation for blind individuals
3. automatic querying of surveillance video
